{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "## Import Library\n",
    "import copy\n",
    "import openai\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import AzureDeveloperCliCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    HnswParameters,\n",
    "    PrioritizedFields,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticSettings,\n",
    "    SimpleField,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmConfiguration,\n",
    ")\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import AzureOpenAI \n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.memory import CosmosDBChatMessageHistory\n",
    "import openai\n",
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "import openai\n",
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "import json\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "#from langchain.retrievers import AzureCognitiveSearchRetriever\n",
    "from langdetect import detect\n",
    "from langchain.prompts import PromptTemplate\n",
    "import re\n",
    "# Create chain to answer questions\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# Import Azure OpenAI\n",
    "from langchain.llms import AzureOpenAI \n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "import openai\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import AzureDeveloperCliCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    HnswParameters,\n",
    "    PrioritizedFields,\n",
    "    SearchableField,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticSettings,\n",
    "    SimpleField,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmConfiguration,\n",
    ")\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from pypdf import PdfReader\n",
    "from langchain.schema import Document\n",
    "import openai\n",
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "#import textwrap\n",
    "import logging\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "import json\n",
    "from docx import Document as DocxDocument\n",
    "from docx.shared import Pt, RGBColor\n",
    "from docx.enum.text import WD_PARAGRAPH_ALIGNMENT\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"credit-proposal\"\n",
    "search_service = \"gptdemosearch\"\n",
    "search_api_key = \"PcAZcXbX2hJsxMYExc2SnkMFO0D94p7Zw3Qzeu5WjYAzSeDMuR5O\"\n",
    "storage_service = \"creditproposal\"\n",
    "storage_api_key = \"hJ2qb//J1I1KmVeDHBpwEpnwluoJzm+b6puc5h7k+dnDSFQ0oxuh1qBz+qPB/ZT7gZvGufwRbUrN+ASto6JOCw==\"\n",
    "connect_str = f\"DefaultEndpointsProtocol=https;AccountName={storage_service};AccountKey={storage_api_key}\"\n",
    "\n",
    "doc_intell_endpoint = \"https://doc-intelligence-test.cognitiveservices.azure.com/\"\n",
    "doc_intell_key = \"9fac3bb92b3c4ef292c20df9641c7374\"\n",
    "\n",
    "# set up openai environment\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://pwcjay.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"f282a661571f45a0bdfdcd295ac808e7\"\n",
    "\n",
    "os.environ[\"AZURE_COGNITIVE_SEARCH_SERVICE_NAME\"] = search_service\n",
    "os.environ[\"AZURE_COGNITIVE_SEARCH_API_KEY\"] = search_api_key\n",
    "os.environ[\"AZURE_INDEX_NAME\"] = index_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up this varible to mock as front end return sector name\n",
    "section = 'Executive Summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_note_txt = \"\"\"Client: Gogovan\n",
    "Industry: Logistics and Delivery Services\n",
    "Date: 20 Nov 2023\n",
    "\n",
    "Meeting Summary:\t\n",
    "Today, I evaluated Gogovan's credit proposal for their expansion plans, technology investments, and working capital needs.\t\n",
    "\n",
    "Client Background:\t\n",
    "Gogovan is a leading logistics and delivery service provider, offering on-demand delivery solutions to individuals and businesses. Established in 2013, the company has rapidly expanded its operations and established a strong presence in the market. Gogovan operates a user-friendly mobile application and web platform, connecting customers with a network of professional drivers and delivery partners.\t\n",
    "\n",
    "Financial Performance:\t\n",
    "Gogovan has demonstrated consistent revenue growth over the past few years, driven by increasing customer adoption and expansion into new markets. The company's financial statements reflect a healthy profitability margin, indicating effective cost management and operational efficiency. Cash flow from operations has been positive, providing a stable source of funds to support working capital requirements and ongoing business operations.\t\n",
    "\n",
    "Market Position and Competitive Landscape:\t\n",
    "Gogovan has successfully positioned itself as a market leader in the logistics and delivery industry, leveraging its strong brand recognition and innovative technology platform. The company has built a robust network of drivers and delivery partners, enabling quick and reliable service fulfillment. Gogovan's competitive advantage lies in its ability to offer cost-effective and flexible solutions tailored to meet the needs of various customer segments, including e-commerce, retail, and individual users.\t\n",
    "\n",
    "Growth Strategy and Market Potential:\t\n",
    "Gogovan has outlined a comprehensive growth strategy focused on expanding its geographical presence, diversifying its service offerings, and enhancing customer experience. The company plans to enter new markets, both domestically and internationally, to capture additional customer segments and increase market share. Gogovan aims to invest in technology and infrastructure improvements to streamline operations, optimize delivery routes, and enhance overall efficiency.\t\n",
    "\n",
    "Risk Assessment:\t\n",
    "The logistics industry is subject to various risks, including intense competition, regulatory changes, and economic downturns. Gogovan has implemented risk mitigation measures such as diversification of services and markets, maintaining strong relationships with key partners, and closely monitoring market trends. Operational risks, such as driver availability, vehicle maintenance, and service disruptions, are managed through rigorous driver screening, continuous training programs, and proactive maintenance schedules. Financial risks are mitigated by maintaining a healthy liquidity position, diversifying funding sources, and prudent financial management practices.\t\n",
    "\n",
    "Credit Request and Repayment Plan:\t\n",
    "Gogovan is requesting a credit facility of $10million to support its expansion plans, technology investments, and working capital needs. The proposed repayment plan consists of regular principal and interest payments over a 3 years term, aligning with the company's projected cash flow generation and financial performance.\t\n",
    "\n",
    "Conclusion:\t\n",
    "Gogovan has demonstrated a strong market position, consistent financial performance, and a well-defined growth strategy. With its robust operational capabilities, innovative technology platform, and customer-centric approach, the company is well-positioned to capitalize on the growing demand for logistics and delivery services. The proposed credit facility, in line with the company's financial projections, will support Gogovan's expansion plans and enable it to maintain its competitive edge in the market.\t\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core LLM call funcition\n",
    "\n",
    "def cap(match):\n",
    "    return(match.group().capitalize())\n",
    "\n",
    "\n",
    "def load_json(json_path):\n",
    "    with open(json_path, \"r\" ,encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "'''\n",
    "    You could follow the below extraction example format to output the answer.\n",
    "    example (Keyword: example):\n",
    "    {example}\n",
    "\n",
    "    3. The example (Keyword: proposal_example) above is just for your reference only to improve your theme, you must not directly copy the content in the examples\n",
    "\n",
    "'''\n",
    "\n",
    "#This funcition is to prepare the rm note in desired format for web, call by app.py\n",
    "def web_extract_RM(section, rm_note_txt):\n",
    "    hierarchy_file_name = \"hierarchy_v2.json\"\n",
    "\n",
    "    hierarchy_dict_list = load_json(hierarchy_file_name)\n",
    "\n",
    "    prompt_template_for_extracting_rm_note = \"\"\"\n",
    "    Read the following context, aggregate the context and answer the input question based on the aggregate context (Keyword: Question):\n",
    "    \n",
    "    Please Just based on the \n",
    "    context: {rm_note}\n",
    "\n",
    "    ======\n",
    "    Question: {question}\n",
    "    ======\n",
    "\n",
    "    Follow the instruction below:\n",
    "    1. Please provide your answer in English\n",
    "    2. Do not start your answer with \"Based on the given information\"\n",
    "    3. If possible, try to expand the information provided from the RM\n",
    "    4. Do not create any figures by make-up \n",
    "    5. Please provide [N/A] as answer if you cannot find any relevant information from the given context. Example Format: [N/A]\n",
    "    \n",
    "    Take a deep breath and work on this step by step\n",
    "    \"\"\"\n",
    "    rm_prompt_template = PromptTemplate(template=prompt_template_for_extracting_rm_note, input_variables=[\"rm_note\", \"question\",])# \"example\",])\n",
    "\n",
    "    llm_rm_note = AzureChatOpenAI(deployment_name=\"gpt-35-16k\", temperature=0.1,\n",
    "                            openai_api_version=\"2023-05-15\", openai_api_base=\"https://pwcjay.openai.azure.com/\")\n",
    "\n",
    "    #\"example\": dictionary[\"Example\"],\n",
    "\n",
    "    output_dict_list = []\n",
    "    for dictionary in hierarchy_dict_list:\n",
    "        if dictionary[\"Section\"] == section:\n",
    "            chain = LLMChain(llm=llm_rm_note, prompt=rm_prompt_template)\n",
    "            dictionary[\"Value\"] = chain({\"rm_note\":rm_note_txt, \"question\": dictionary[\"Question\"]})['text']\n",
    "            dictionary[\"Value\"] = dictionary[\"Value\"].replace(\"Based on the given information, \", \"\")\n",
    "            if \"[N/A]\" in dictionary[\"Value\"]:\n",
    "                dictionary[\"Value\"] = \"\"\n",
    "            output_dict_list.append(dictionary)\n",
    "\n",
    "    # Create Json file \n",
    "    # output_json_name = \"GOGOVAN_hierarchy_rm_note.json\"\n",
    "    # json.dump(output_dict_list, open(output_json_name, \"w\"), indent=4)\n",
    "\n",
    "    return output_dict_list\n",
    "\n",
    "'''\n",
    "        ======\n",
    "        Example: (Keyword: proposal_example)\n",
    "        {example}\n",
    "        ======\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def first_gen_template():\n",
    "    proposal_proposal_template_text = \"\"\"\n",
    "        Read the input json for this section carefully and aggregate the content of \"Value\" key:\n",
    "\n",
    "        Please follow the format in content of \"example\" key to output the answer\n",
    "        But please do not include any content in \"example\" key to output the answer, as it just use as reference\n",
    "\n",
    "\n",
    "        Read the input json for this section carefully and aggregate the content of \"Value\" key\n",
    "        please based on the content in \"Value\" key to output the answer\n",
    "        Input JSON:\n",
    "        {input_json}\n",
    "        \n",
    "        Then write paragraph(s) based on the above aggregrated context \n",
    "\n",
    "        Rules you need to follow:\n",
    "        1. Don't mention the word \"RM Note\" and \"Component\", and don't mention you held a meeting with the client! Instead, you shall say \"It is mentioned that\"\n",
    "        2. Don't mention the source of your input (i.e. RM Note (Keyword: rm_note), example, document)\n",
    "        3. Don't justify your answers\n",
    "        4. Don't provide suggestion or recommendation by yourself\n",
    "        5. Provide your answer in English\n",
    "        6. Breake it to multi-paragraphs if one single paragraph consists of more than 100 words\n",
    "        7. In the same paragraph, don't input line breaks among the sentences\n",
    "        8. Don't start with your answer by a title. You must start your paragraph immediately\n",
    "        9. The example (Keyword: proposal_example) above is just for your reference only to improve your theme, you must not directly copy the content in the examples\n",
    "        10. If possible, you can use point-form, tables to provide your answer\n",
    "        11. Don't introduce what this section includes\n",
    "\n",
    "        Guidance when you do not have the information:\n",
    "        1. When you don't have the specific information or you need further information (Keyword: further_info), you have to write it in the following format: [RM please helps provide the further information of (Keyword: further_info)], where please supplement the information you need here.\n",
    "        2. You must not create the information by yourself if you don't have relevant information\n",
    "        3. You cannot say \"It's unclear that\", please refer to point 1 for the formatting for requesting further information\n",
    "\n",
    "        Take a deep breath and work on this step by step\n",
    "        \"\"\"\n",
    "    prompt_template_proposal = PromptTemplate(template=proposal_proposal_template_text, input_variables=[\"input_json\"])\n",
    "\n",
    "\n",
    "    return prompt_template_proposal\n",
    "\n",
    "\n",
    "def regen_template():\n",
    "    proposal_proposal_template_text = \"\"\"\n",
    "        Read the previous_paragraph, RM instruction for this section carefully:\n",
    "        \n",
    "        Please follow the previous paragraph and RM instruction and return a summarize paragraph in human readable form:\n",
    "        {previous_paragraph}\n",
    "\n",
    "        ======================================\n",
    "\n",
    "        Please follow the RM instruction to edit the previous_paragraph and return a summarize paragraph in human readable form:\n",
    "        You could treat the RM instruction as prompt.\n",
    "        RM instruction:\n",
    "        {rm_instruction}\n",
    "        ======================================\n",
    "\n",
    "        Then write paragraph(s) based on the above aggregrated context\n",
    "\n",
    "        Rules you need to follow:\n",
    "        1. Don't mention the word \"RM Note\" and \"Component\", and don't mention you held a meeting with the client! Instead, you shall say \"It is mentioned that\"\n",
    "        2. Don't mention the source of your input (i.e. RM Note (Keyword: rm_note), example, document)\n",
    "        3. Don't justify your answers\n",
    "        4. Don't provide suggestion or recommendation by yourself\n",
    "        5. Provide your answer in English\n",
    "        6. Breake it to multi-paragraphs if one single paragraph consists of more than 100 words\n",
    "        7. In the same paragraph, don't input line breaks among the sentences\n",
    "        8. Don't start with your answer by a title. You must start your paragraph immediately\n",
    "        9. The example (Keyword: proposal_example) above is just for your reference only to improve your theme, you must not directly copy the content in the examples\n",
    "        10. If possible, you can use point-form, tables to provide your answer\n",
    "        11. Don't introduce what this section includes\n",
    "\n",
    "        Guidance when you do not have the information:\n",
    "        1. When you don't have the specific information or you need further information (Keyword: further_info), you have to write it in the following format: [RM please helps provide the further information of (Keyword: further_info)], where please supplement the information you need here.\n",
    "        2. You must not create the information by yourself if you don't have relevant information\n",
    "        3. You cannot say \"It's unclear that\", please refer to point 1 for the formatting for requesting further information\n",
    "\n",
    "        Take a deep breath and work on this step by step\n",
    "        \"\"\"\n",
    "    prompt_template_proposal = PromptTemplate(template=proposal_proposal_template_text, input_variables=[\"previous_paragraph\", \"rm_instruction\"])\n",
    "\n",
    "\n",
    "    return prompt_template_proposal\n",
    "\n",
    "\n",
    "# to first generate \n",
    "def first_generate(section_name, input_json):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    A core function to generate the proposal per section\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    prompt: str\n",
    "    Prompt text for instructing the output based on RM prompt\n",
    "\n",
    "    rm_note: str\n",
    "    It contains the information from the RM\n",
    "\n",
    "    example: str\n",
    "    Input example for GPt to take it as an example\n",
    "\n",
    "    \"\"\"\n",
    "    #.format(content=content, section=section, context=context)\n",
    "    \n",
    "    prompt_template_proposal = first_gen_template()\n",
    "\n",
    "    llm_proposal = AzureChatOpenAI(deployment_name=\"gpt-35-16k\", temperature=0,\n",
    "                            openai_api_version=\"2023-05-15\", openai_api_base=\"https://pwcjay.openai.azure.com/\")\n",
    "    \n",
    "    chain = LLMChain(\n",
    "        llm=llm_proposal,\n",
    "        prompt=prompt_template_proposal\n",
    "    )\n",
    "\n",
    "    drafted_text = chain({\"input_json\": input_json\n",
    "                    ,})['text']\n",
    "    drafted_text2 = drafted_text.replace(\"Based on the given information, \", \"\").replace(\"It is mentioned that \", \"\")\n",
    "    \n",
    "    #All capital letters for first letter in sentences\n",
    "    formatter = re.compile(r'(?<=[\\.\\?!]\\s)(\\w+)')\n",
    "    drafted_text2 = formatter.sub(cap, drafted_text2)\n",
    "\n",
    "    \n",
    "    rm_fill_values = []\n",
    "    additional_info_values = []\n",
    "    lines = drafted_text2.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        match = re.search(r\"\\[RM .+?\\]\", line)\n",
    "        if match:\n",
    "            rm_fill = match.group(0)\n",
    "            # Remove the '[RM ' at the start and ']' at the end, then append\n",
    "            rm_fill = rm_fill.replace('[RM ', '', 1)\n",
    "            rm_fill = rm_fill[:-1] # remove the closing bracket\n",
    "            rm_fill_values.append(rm_fill)\n",
    "            line = line.replace(rm_fill, \"\")\n",
    "                \n",
    "        # Check for \"Please provide further information\" in the line\n",
    "        if \"Please provide further information\" in line:\n",
    "            # Append the whole line\n",
    "            additional_info_values.append(line)\n",
    "\n",
    "    # Join all the strings in the list with a space in between each string\n",
    "    rm_fill_text = ' '.join(rm_fill_values)\n",
    "    additional_info_text = ' '.join(additional_info_values)\n",
    "\n",
    "    # Combine rm_fill_text and additional_info_text into one string\n",
    "    combined_text = rm_fill_text + ' ' + additional_info_text\n",
    "\n",
    "    output_json = {\n",
    "        \"section\": section_name,\n",
    "        \"output\": drafted_text2,\n",
    "        \"RM fill\" : combined_text,\n",
    "    }\n",
    "    #output the result\n",
    "    return output_json\n",
    "\n",
    "def run_first_gen(section, rm_note_txt):\n",
    "\n",
    "    extract_json = web_extract_RM(section ,rm_note_txt)\n",
    "    output_json = first_generate(section, extract_json)\n",
    "\n",
    "    return output_json\n",
    "\n",
    "def regen(section_name, previous_paragraph, rm_instruction):\n",
    "    prompt_template_proposal = regen_template()\n",
    "\n",
    "    llm_proposal = AzureChatOpenAI(deployment_name=\"gpt-35-16k\", temperature=0,\n",
    "                            openai_api_version=\"2023-05-15\", openai_api_base=\"https://pwcjay.openai.azure.com/\")\n",
    "    \n",
    "    chain = LLMChain(\n",
    "        llm=llm_proposal,\n",
    "        prompt=prompt_template_proposal\n",
    "    )\n",
    "\n",
    "    drafted_text = chain({\"previous_paragraph\": previous_paragraph\n",
    "                    ,\"rm_instruction\":rm_instruction})['text']\n",
    "    drafted_text2 = drafted_text.replace(\"Based on the given information, \", \"\").replace(\"It is mentioned that \", \"\")\n",
    "    \n",
    "    #All capital letters for first letter in sentences\n",
    "    formatter = re.compile(r'(?<=[\\.\\?!]\\s)(\\w+)')\n",
    "    drafted_text2 = formatter.sub(cap, drafted_text2)\n",
    "\n",
    "    rm_fill_values = []\n",
    "    additional_info_values = []\n",
    "    lines = drafted_text2.split(\"\\n\")\n",
    "    for line in lines:\n",
    "        match = re.search(r\"\\[RM .+?\\]\", line)\n",
    "        if match:\n",
    "            rm_fill = match.group(0)\n",
    "            # Remove the '[RM ' at the start and ']' at the end, then append\n",
    "            rm_fill = rm_fill.replace('[RM ', '', 1)\n",
    "            rm_fill = rm_fill[:-1] # remove the closing bracket\n",
    "            rm_fill_values.append(rm_fill)\n",
    "            line = line.replace(rm_fill, \"\")\n",
    "                \n",
    "        # Check for \"Please provide further information\" in the line\n",
    "        if \"Please provide further information\" in line:\n",
    "            # Append the whole line\n",
    "            additional_info_values.append(line)\n",
    "\n",
    "    # Join all the strings in the list with a space in between each string\n",
    "    rm_fill_text = ' '.join(rm_fill_values)\n",
    "    additional_info_text = ' '.join(additional_info_values)\n",
    "\n",
    "    # Combine rm_fill_text and additional_info_text into one string\n",
    "    combined_text = rm_fill_text + ' ' + additional_info_text\n",
    "\n",
    "    output_json = {\n",
    "        \"section\": section_name,\n",
    "        \"output\": drafted_text2,\n",
    "        \"RM fill\" : combined_text,\n",
    "    }\n",
    "    #output the result\n",
    "    return output_json\n",
    "\n",
    "def create_docx(client_name, json_data):\n",
    "    # Create a new Word document\n",
    "    document = DocxDocument()\n",
    "\n",
    "    title_text = \"Credit Proposal for \" + client_name\n",
    "    title_size = 20 # Font size in points\n",
    "\n",
    "    # Create a paragraph for the title\n",
    "    title_paragraph = document.add_paragraph()\n",
    "\n",
    "    # Add the title text to the paragraph\n",
    "    title_run = title_paragraph.add_run(title_text)\n",
    "\n",
    "    # Apply formatting to the title run\n",
    "    title_run.bold = True\n",
    "    title_run.font.size = Pt(title_size)\n",
    "\n",
    "    # Set the alignment of the paragraph to the center\n",
    "    title_paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER\n",
    "\n",
    "    # Convert JSON values to section headers and paragraphs in the Word document\n",
    "    for item in json_data['consolidated_text']:\n",
    "        section = item['section']\n",
    "        context = item['output']\n",
    "\n",
    "        # Add the section header\n",
    "        document.add_heading(section, level=1)\n",
    "\n",
    "        # Split context into lines and check each line\n",
    "        for line in context.split('\\n'):\n",
    "            # Create a new paragraph for each line\n",
    "            paragraph = document.add_paragraph()\n",
    "\n",
    "            # Search for the pattern [RM please ... ] using regex\n",
    "            matches = re.findall(r'\\[RM .*?\\]', line)\n",
    "\n",
    "            if matches:\n",
    "                # If there's a match, split line into parts\n",
    "                parts = re.split(r'(\\[RM .*?\\])', line)\n",
    "\n",
    "                for part in parts:\n",
    "                    run = paragraph.add_run(part)\n",
    "\n",
    "                    if part in matches:\n",
    "                        # This part should be colored red\n",
    "                        run.font.color.rgb = RGBColor(255, 0, 0)  # RGB values for red\n",
    "            else:\n",
    "                # Normal text\n",
    "                run = paragraph.add_run(line)\n",
    "\n",
    "    # Save the Word document\n",
    "    document.save(client_name + '_Word_proposal.docx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'Executive Summary',\n",
       " 'output': \"the Executive Summary provides an overview of the proposal. Gogovan has submitted a credit proposal for their expansion plans, technology investments, and working capital needs. The company is requesting a credit facility of $10 million, which will be used to support their growth strategy. The proposed repayment plan consists of regular principal and interest payments over a 3-year term.\\n\\nGogovan has demonstrated a strong market position, consistent financial performance, and a well-defined growth strategy. They have a user-friendly mobile application and web platform that connects customers with a network of professional drivers and delivery partners. The company has shown consistent revenue growth, profitability, and positive cash flow from operations. Gogovan has positioned itself as a market leader in the logistics and delivery industry, with a strong brand recognition and innovative technology platform. They offer cost-effective and flexible solutions tailored to meet the needs of various customer segments.\\n\\nGogovan plans to expand its geographical presence, diversify its service offerings, and enhance customer experience. They aim to invest in technology and infrastructure improvements to streamline operations and optimize delivery routes. The company has implemented risk mitigation measures and maintains a healthy liquidity position. Overall, the proposed credit facility aligns with Gogovan's financial projections and will support their expansion plans and competitive edge in the market.\",\n",
       " 'RM fill': ' '}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_first_gen(section, rm_note_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section': 'Executive Summary',\n",
       " 'output': 'Gogovan is seeking a credit facility of $80 million instead of $10 million to support their expansion plans, technology investments, and working capital needs. The proposed repayment plan still consists of regular principal and interest payments over a 3-year term. \\n\\nGogovan aims to expand its geographical presence, diversify its service offerings, and enhance customer experience with the increased credit facility. However, specific details regarding their expansion plans, technology investments, and working capital needs are not provided in the given information. \\n\\n[RM please help provide further information on the specific expansion plans, technology investments, and working capital needs of Gogovan.]',\n",
       " 'RM fill': 'please help provide further information on the specific expansion plans, technology investments, and working capital needs of Gogovan. '}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_paragraph = run_first_gen(section, rm_note_txt)\n",
    "previous_paragraph['output']\n",
    "regen(section, previous_paragraph['output'], \"Gogovan is requesting a credit facility of $80 million instead of 10 million\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "json_data = {\n",
    "    \"consolidated_text\":[\n",
    "        {\n",
    "            \"section\":\"xxx\",\n",
    "            \"output\":\"xxx\"\n",
    "        },\n",
    "        {\n",
    "            \"section\":\"yyy\",\n",
    "            \"output\":\"yyy\"\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_docx('GOGOX', json_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
